{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30185,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Saving a Cats v Dogs Model","metadata":{"id":"98d53c05"}},{"cell_type":"markdown","source":"This is a minimal example showing how to train a fastai model on Kaggle, and save it so you can use it in your app.","metadata":{}},{"cell_type":"code","source":"# Make sure we've got the latest version of fastai:\n!pip install -Uqq fastai","metadata":{"id":"evvA0fqvSblq","outputId":"ba21b811-767c-459a-ccdf-044758720a55","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-20T04:46:22.637710Z","iopub.execute_input":"2024-01-20T04:46:22.637992Z","iopub.status.idle":"2024-01-20T04:46:45.379337Z","shell.execute_reply.started":"2024-01-20T04:46:22.637907Z","shell.execute_reply":"2024-01-20T04:46:45.378545Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntensorflow 2.6.3 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\ntensorflow 2.6.3 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.3 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\ntensorflow 2.6.3 requires wrapt~=1.12.1, but you have wrapt 1.14.0 which is incompatible.\ntensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.3 which is incompatible.\nrich 12.2.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.6.1 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npytools 2022.1.5 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\napache-beam 2.37.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.37.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\napache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\naioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.2.0 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"First, import all the stuff we need from fastai:","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import *","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-01-20T04:53:48.916018Z","iopub.execute_input":"2024-01-20T04:53:48.916515Z","iopub.status.idle":"2024-01-20T04:53:48.921512Z","shell.execute_reply.started":"2024-01-20T04:53:48.916463Z","shell.execute_reply":"2024-01-20T04:53:48.920637Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Download and decompress our dataset, which is pictures of woof:","metadata":{}},{"cell_type":"code","source":"path = untar_data(URLs.IMAGEWOOF)/'train'","metadata":{"execution":{"iopub.status.busy":"2024-01-20T04:56:48.199028Z","iopub.execute_input":"2024-01-20T04:56:48.199517Z","iopub.status.idle":"2024-01-20T04:56:48.204635Z","shell.execute_reply.started":"2024-01-20T04:56:48.199461Z","shell.execute_reply":"2024-01-20T04:56:48.203785Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"We need a way to label our images as dogs or cats. In this dataset, pictures of cats are given a filename that starts with a capital letter:","metadata":{}},{"cell_type":"code","source":"def is_woof(x): return x[0].isupper() ","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-01-20T04:56:49.672294Z","iopub.execute_input":"2024-01-20T04:56:49.673111Z","iopub.status.idle":"2024-01-20T04:56:49.677449Z","shell.execute_reply.started":"2024-01-20T04:56:49.673063Z","shell.execute_reply":"2024-01-20T04:56:49.676554Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Now we can create our `DataLoaders`:","metadata":{}},{"cell_type":"code","source":"dls = ImageDataLoaders.from_name_func('.',\n    get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_woof,\n    item_tfms=Resize(192))","metadata":{"id":"44eb0ad3","execution":{"iopub.status.busy":"2024-01-20T04:56:51.192891Z","iopub.execute_input":"2024-01-20T04:56:51.193178Z","iopub.status.idle":"2024-01-20T04:56:55.017606Z","shell.execute_reply.started":"2024-01-20T04:56:51.193146Z","shell.execute_reply":"2024-01-20T04:56:55.016709Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"... and train our model, a resnet18 (to keep it small and fast):","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)","metadata":{"id":"c107f724","outputId":"fcc1de68-7c8b-43f5-b9eb-fcdb0773ef07","execution":{"iopub.status.busy":"2024-01-20T04:59:09.946912Z","iopub.execute_input":"2024-01-20T04:59:09.947862Z","iopub.status.idle":"2024-01-20T05:02:07.860230Z","shell.execute_reply.started":"2024-01-20T04:59:09.947808Z","shell.execute_reply":"2024-01-20T05:02:07.859148Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ae3731ced94f16a9a411070aa7c6ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.675353</td>\n      <td>0.271231</td>\n      <td>0.090859</td>\n      <td>00:47</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>error_rate</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.256158</td>\n      <td>0.172022</td>\n      <td>0.036011</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.189758</td>\n      <td>0.182473</td>\n      <td>0.035457</td>\n      <td>00:42</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.119494</td>\n      <td>0.176547</td>\n      <td>0.036011</td>\n      <td>00:43</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can export our trained `Learner`. This contains all the information needed to run the model:","metadata":{}},{"cell_type":"code","source":"learn.export('model.pkl')","metadata":{"id":"ae2bc6ac","execution":{"iopub.status.busy":"2024-01-20T05:15:30.251042Z","iopub.execute_input":"2024-01-20T05:15:30.251936Z","iopub.status.idle":"2024-01-20T05:15:30.427781Z","shell.execute_reply.started":"2024-01-20T05:15:30.251865Z","shell.execute_reply":"2024-01-20T05:15:30.426932Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Finally, open the Kaggle sidebar on the right if it's not already, and find the section marked \"Output\". Open the `/kaggle/working` folder, and you'll see `model.pkl`. Click on it, then click on the menu on the right that appears, and choose \"Download\". After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.","metadata":{"id":"Q2HTrQKTf3BV"}}]}